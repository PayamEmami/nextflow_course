--- 
title: "Introduction to Nextflow"
author: "Payam Emami"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
description: |
 This is a short tutorial about Nextflow. 
link-citations: yes
github-repo: rstudio/bookdown-demo
output:
  bookdown::html_document2:
    includes:
      in_header: header.html
  bookdown::gitbook:
    includes:
      in_header: header.html
---

```{r setup, include=FALSE}
# Add a common class name for every chunks
knitr::opts_chunk$set(
  echo = TRUE)
```
```{r htmlTemp3, echo=FALSE, eval=TRUE}
install.packages("readr")
codejs <- readr::read_lines("js/codefolding.js")
collapsejs <- readr::read_lines("js/collapse.js")
transitionjs <- readr::read_lines("js/transition.js")

htmlhead <- 
  paste('
<script>',
paste(transitionjs, collapse = "\n"),
'</script>
<script>',
paste(collapsejs, collapse = "\n"),
'</script>
<script>',
paste(codejs, collapse = "\n"),
'</script>
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
.row { display: flex; }
.collapse { display: none; }
.in { display:block }
</style>
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "hide");
});
</script>
', sep = "\n")

readr::write_lines(htmlhead, path = "header.html")
```

# Introduction

Welcome to this short tutorial on Nextflow. We are going to walk through some of the functionalities of this powerful workflow engine. More specifically we are going to do some hands-on work on processes, channels and operators. We are also going to look into how to configure Nextflow to run on different platforms. But before moving forward, we need to set up the environment for using Nextflow. 

## Setting up the environment

We are going to use UPPMAX for doing most of the handson work. 

First ssh to UPPMAX

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
ssh -AX youusername@rackham.uppmax.uu.se
```

Make a directory in your user space (only if you have not done before)

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
mkdir -p /crex/proj/uppmax2022-2-10/nobackup/$USER/nextflow_lab1
```

Navigate to the folder you have created

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
cd /crex/proj/uppmax2022-2-10/nobackup/$USER/nextflow_lab1
```

Load Nexflow

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
module load bioinfo-tools
module load Nextflow/20.10.0
```

If because of any reason, you cannot use UPPMAX, Nextflow can be installed on any POSIX compatible system for example Linux, OS X, Windows Subsystem for Linux. Head to [Nextflow website](https://www.nextflow.io/docs/latest/getstarted.html#installation) and follow the installation procedure.

# Basic concepts

Nextflow is a reactive workflow framework and a programming DSL that eases the writing of data-intensive computational pipelines.

It is designed around the idea that the Linux platform is the lingua franca of data science. Linux provides many simple but powerful command-line and scripting tools that, when chained together, facilitate complex data manipulations.

Nextflow extends this approach, adding the ability to define complex program interactions and a high-level parallel computational environment based on the dataflow programming model.

## Nextflow scripting 

The Nextflow scripting language is an extension of the Groovy programming language. Groovy is a powerful programming language for the Java virtual machine. The Nextflow syntax has been specialized to ease the writing of computational pipelines in a declarative manner.

Nextflow can execute any piece of Groovy code or use any library for the JVM platform.

For example,



```{r attr.source='.numberLines',eval=FALSE, class.source="nohide"}
println "Hello, World!" #1
 
x = 1 #2
println x
 
x = new java.util.Date() #2
println x
 
x = -3.1499392 #2
println x
 
x = false #2
println x
 
x = "Hi" #2
println x

myList = [1776, -1, 33, 99, 0, 928734928763] #3
println myList

square = { it * it } #4
println square(9)
 
printMapClosure = { key, value ->
   println "$key = $value"
} #4

map_example=[ "Yue" : "Wu", "Mark" : "Williams", "Sudha" : "Kumari" ] #5


[ "Yue" : "Wu", "Mark" : "Williams", "Sudha" : "Kumari" ].each(printMapClosure) #6


```

1. To print something is as easy as using one of the print or println methods
2. To define a variable, simply assign a value to it
3. A List object can be defined by placing the list items in square brackets
4. A closure is a block of code that can be passed as an argument to a function. Thus, you can define a chunk of code and then pass it around as if it were a string or an integer
5. Maps are used to store associative arrays or dictionaries. They are unordered collections of heterogeneous, named data
6. the method Map.each() can take a closure with two arguments, to which it binds the key and the associated value for each key-value pair in the Map

To test this, Create a file called `main_2.nf` using your favorite editor (i use nano)

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
nano main_2.nf
```

Copy and paste the script above. Save the file `(Ctrl+o enter)` and exit `(Ctrl+x)`
Run the following command:

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
nextflow main_2.nf
```

There are many other things that can be done with Groovy scripts. Please have a look at [Nextflow scripting
](https://www.nextflow.io/docs/latest/script.html#)

## Processes and channels

In practice a Nextflow pipeline script is made by joining together different `processes`. Each process can be written in any scripting language that can be executed by the Linux platform (Bash, Perl, Ruby, Python, etc.).

Processes are executed independently and are isolated from each other, i.e. they do not share a common (writable) state. The only way they can communicate is via asynchronous FIFO queues, called `channels` in Nextflow.

Any process can define one or more channels as input and output. The interaction between these processes, and ultimately the pipeline execution flow itself, is implicitly defined by these input and output declarations.


# Channels

We start with `channels` as they are more resemble the variable in a typical programming language. Nextflow is based on the Dataflow programming model in which processes communicate through channels. Using these channels we can connect different processes together. 

There are two different types of channel in Nextflow:

1. A queue channel is a non-blocking unidirectional FIFO queue which connects two processes or operators. *The same queue channel cannot be used more than one time as*
2. A value channel a.k.a. singleton channel by definition is bound to a single value and it can be read unlimited times without consuming its content.

We are going to focus on queue channels here. A queue channel is usually created using a factory method such as a from, fromPath, etc.

## of

The `of` method allows you to create a channel emitting any sequence of values that are specified as the method argument

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
println "Channel.of( 1, 3, 5, 7 ):"
ch = Channel.of( 1, 3, 5, 7 ) #1 
ch.view()

println "Channel.of( [1, 3, 5, 7, 9]):"
ch = Channel.of( [1, 3, 5, 7, 9]) #2
ch.view()

```

1. Creates a channel from a sequence of values and set the name to ch
2. Creates a channel from a list of values

Create a file called `main_3.nf`

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
nano main_3.nf
```

Copy the above code to it. Save the file `(Ctrl+o enter)` and exit `(Ctrl+x)`
Now run 

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
nextflow main_3.nf
```


## fromPath

You can create a channel emitting one or more file paths by using the fromPath method and specifying a path string as an argument.


```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
// single file
myFileChannel = Channel.fromPath( '/crex/proj/uppmax2022-2-10/metabolomics/mzMLData/Blank10.mzML' ) #1
myFileChannel.view()
// multiple files
myFileChannel = Channel.fromPath( '/crex/proj/uppmax2022-2-10/metabolomics/mzMLData/*.*' ) #2
myFileChannel.view()
// recursive multiple files
myFileChannel = Channel.fromPath( '/crex/proj/uppmax2022-2-10/metabolomics/**.*' ) #3
myFileChannel.view()

```

1. Creates a channel and binds to it a Path item referring the specified file.
2. Whenever the `fromPath` argument contains a `*` or `?` wildcard character it is interpreted as a `glob` path matcher.
3. Two asterisks, i.e. `**`, works like `*` but crosses directory boundaries.

Create a file called `main_4.nf`

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
nano main_4.nf
```

Copy the above code to it. Save the file `(Ctrl+o enter)` and exit `(Ctrl+x)`
Now run 

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
nextflow main_4.nf
```


There are many parameters as well as channel types that can be used for different purposes. Please check the (documentation)[https://www.nextflow.io/docs/latest/channel.html].


# Processes

In Nextflow a process is the basic processing primitive to execute a user script. As said before, this processes can pretty much run anything from R scripts to complex bash commands. Anything that is executable on the linux system can be run!

The process definition starts with keyword the process, followed by process name and finally the process body delimited by curly brackets. The process body must contain a string which represents the command or, more generally, a script that is executed by it.

The overall structure of a process in Nextflow looks like this:

```{r attr.source='.numberLines',eval=FALSE, class.source="nohide"}
process < name > {

   [ directives ] #1

   input:
    < process inputs > #2

   output:
    < process outputs > #3

   when:
    < condition > #4

   [script|shell|exec]:
   < user script to be executed > #5

}
```

1. Using the directive declarations block you can provide optional settings that will affect the execution of the current process
2. The input block defines from which channels the process expects to receive data.
3. The output declaration block allows you to define the channels used by the process to send out the results produced. 
4. The `when` declaration allows you to define a condition that must be verified in order to execute the process. 
5. The script block is a string statement that defines the command that is executed by the process to carry out its task.

## script|shell|exec

We start with the `script` block. A process contains one and only one script block, and it must be the last statement when the process contains input and output declarations. The entered string is executed as a Bash script in the host system. It can be any command, script or combination of them, that you would normally use in terminal shell or in a common Bash script. The script block can be a simple string or multi-line string. The latter simplifies the writing of non trivial scripts composed by multiple commands spanning over multiple lines. If you would like to run shell instead of bash you can use single quotation (`'''`) instead of double. 

For example,

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
db='database' #1

process justEchoBash {
echo true #2
 script:
 """
 echo $db #3
 """

}

process justEchoShell {
echo true
   shell:
   '''
   echo !{db} #4
   '''
}

```

1. Creates a variable and assign it to `database`. 
2. This is a directive that is setting the process to print the standard output. More on this later!
3. Runs the bash command `cat` which prints the content of variable `db`. Note that the variables that you define outside of the process script can be accessed using `$` sign
4. This is identical to bash but using shell. To access the variable `db` we need to wrap in `!{}`

Please note that unless really needed try to use `bash`. 

Create a file called `main_5.nf`

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
nano main_5.nf
```

Copy the above code to it. Save the file `(Ctrl+o enter)` and exit `(Ctrl+x)`
Now run 

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
nextflow main_5.nf
```


## input

The input block defines from which channels the process expects to receive data. You can only define one input block at a time and it must contain one or more input declarations.

The input block follows the syntax shown below:


```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
input:
  <input qualifier> <input name> [from <source channel>] [attributes]
```

An input definition starts with an input qualifier and the input name, followed by the keyword from and the actual channel over which inputs are received. Finally some input optional attributes can be specified. 

The input qualifier declares the type of data to be received. 

The qualifiers available are the ones listed in the following table:

| Qualifier | Semantic                                                                                          |
|-----------|---------------------------------------------------------------------------------------------------|
| val       | Lets you access the received input value by its name in the process script.                       |
| env       | Lets you use the received value to set an environment variable named as the specified input name. |
| file      | Lets you handle the received value as a file, staging it properly in the execution context.       |
| path      | Lets you handle the received value as a path, staging the file properly in the execution context. |
| stdin     | Lets you forward the received value to the process stdin special file.                            |
| tuple     | Lets you handle a group of input values having one of the above qualifiers.                       |
| each      | Lets you execute the process for each entry in the input collection.                              |

For example, here we are a channel and a process that gets an input the channel and prits the values.

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
num = Channel.from( 1, 2, 3 ) #1

process basicExample {
echo true
 input:
 val x from num #2
 "echo process job $x" #3
}

```

1. Creates a channel of 1,2,3
2. Set the input of the process to the channel `num`. The type of the channel is `val`.
3. Runs a simple echo command that writes the value to std out! Remember that to access the input we need to use `$x`.

In the above example the process is executed three times, each time a value is received from the channel num and used to process the script. 

Create a file called `main_6.nf`

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
nano main_6.nf
```

Copy the above code to it. Save the file `(Ctrl+o enter)` and exit `(Ctrl+x)`
Now run 

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
nextflow main_6.nf
```

Can you create a workflow that reads all the files with `*.mzML` extension in a file channel and print their name in a process? Remember, this is a file channel!

```{bash, attr.source='.numberLines',eval=FALSE}
mzMLFiles = Channel.fromPath( '/crex/proj/uppmax2022-2-10/metabolomics/mzMLData/*.mzML' )

process featureFinder {
echo true
 input:
 file mzML from mzMLFiles

 """
echo i’m processing $mzML file!
"""

}

```

Create a file called `main_7.nf` and put write the code.

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
nano main_7.nf
```

Save the file (Ctrl+o enter) and exit (Ctrl+x). Now run 
```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
run main_7.nf
```

### input each

The each qualifier allows you to repeat the execution of a process for each item in a collection, every time a new data is received. 


```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
mzMLFiles = Channel.fromPath( '/crex/proj/uppmax2022-2-10/metabolomics/mzMLData/*.mzML' ) #1
num = Channel.from( 1, 2, 3 ) #2
process featureFinder {
  echo true
input:
each x from num #3
file y from mzMLFiles #4

"echo value $x file $y" #5

}

```

1. Creates a file channel from all `mzML` files in `/crex/proj/uppmax2022-2-10/metabolomics/mzMLData/*.mzML'`.  
2. Create a value type channel
3. Define input repeater for the value channel
4. Define another input channel from the file channel 

In the above example every time a file (`y`) of `mzML` is received as input by the process, it executes three tasks running a `echo` with a different value for the x parameter. This is useful when you need to repeat the same task for a given set of parameters.

Create a file called `main_8.nf`

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
nano main_8.nf
```

Copy the above code to it. Save the file `(Ctrl+o enter)` and exit `(Ctrl+x)`
Now run 

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
nextflow main_8.nf
```

## Output

The output declaration block allows you to define the channels used by the process to send out the results produced. You can only define one output block at a time and it must contain one or more output declarations.

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
output:
<output qualifier> <output name> [into <target channel>[,channel,..]] [attribute [,..]]

```

The qualifiers that can be used in the output declaration block are the ones listed in the following table:

| Qualifier | Semantic                                                                                               |
|-----------|--------------------------------------------------------------------------------------------------------|
| val       | Sends variables with the name specified over the output channel.                                       |
| file      | Sends a file produced by the process with the name specified over the output channel.                  |
| path      | Sends a file produced by the process with the name specified over the output channel (replaces file).  |
| env       | Sends the variable defined in the process environment with the name specified over the output channel. |
| stdout    | Sends the executed process stdout over the output channel.                                             |
| tuple     | Sends multiple values over the same output channel.                                                    |


For example,

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
mzMLFiles = Channel.fromPath( '/crex/proj/uppmax2022-2-10/metabolomics/mzMLData/*.mzML' ) #1
process featureFinder {
input:
file x from mzMLFiles #2
output:
file "output/${x.baseName}.featureXML" into outputChannel #3

""" 
mkdir output 
cp -in $x output/${x.baseName}.featureXML 
"""  #5
}
outputChannel.view()

```

In the above example the process, when executed, it will create a file channel from `/crex/proj/uppmax2022-2-10/metabolomics/mzMLData/*.mzML`. The process will then get this channel as an input and creates an output channel `outputChannel` where each file extension has been changed to `featureXML`. 

1. Creates a channel emitting files.
2. Use the created channel as an input to the process
3. create output channel and put the output file in it. The output file is located under `output` directory. `${x.baseName}` gives the name of the file without extension.
4. In the bash script, we first create an output folder We then copy the input to the output folder but change its extension. This is obviously a pretty useless command! But you can change this to a more meaningful one!

Create a file called `main_9.nf`

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
nano main_9.nf
```

Copy the above code to it. Save the file `(Ctrl+o enter)` and exit `(Ctrl+x)`
Now run 

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
nextflow main_9.nf
```

## Directives

Using the directive declarations block you can provide optional settings that will affect the execution of the current process.

They must be entered at the top of the process body, before any other declaration blocks (i.e. input, output, etc) and have the following syntax:

You can see the complete list of directives [here](https://www.nextflow.io/docs/latest/process.html#directives)


### publishDir

The `publishDir` directive allows you to publish the process output files to a specified folder. 


```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
process foo {

    publishDir '/data/chunks' #1

    output:
    file 'chunk_*' into letters

    '''
    printf 'Hola' | split -b 1 - chunk_
    '''
}
```

The above example splits the string Hola into file chunks of a single byte. 

1. When complete the chunk_* output files are published into the /data/chunks folder.

*Can you create a workflow having a single process that just creates a text file (with whatever content) as an output and also publish its output to a directory?*

```{bash, attr.source='.numberLines',eval=FALSE}
process simpleOutput {
publishDir 'testOutput'
output:
file "test.txt" into outputChannel
"echo test >> test.txt"

}
```


### tag

The `tag` directive allows you to associate each process execution with a custom label, so that it will be easier to identify them in the log file or in the trace execution report.


```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
mzMLFiles = Channel.fromPath( '/crex/proj/uppmax2022-2-10/metabolomics/mzMLData/*.mzML' )
num = Channel.from( 1, 2, 3 )
process featureFinder {
tag "$y" #1
input:
each x from num
file y from mzMLFiles

"""
echo value $x file $y
"""

}
```

In the above example, when a file is received by the process, it will show its name when running the process.

1. `$y` in the tag, indicates that name of file from `mzMLFiles` should be used as tag.

Create a file called `main_9.nf`

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
nano main_12.nf
```

Copy the above code to it. Save the file `(Ctrl+o enter)` and exit `(Ctrl+x)`
Now run 

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
nextflow main_12.nf
```

What do you see? What is the difference to a process without a tag?

# Operators

Nextflow operators are methods that allow you to connect channels to each other or to transform values emitted by a channel applying some user provided rules. There is a large number of operators that can be seen [here](https://www.nextflow.io/docs/latest/operator.html). We go through some of them!

## Collect

The `collect` operator collects all the items emitted by a channel to a List and return the resulting object as a *sole* emission.

For example,


```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
mzMLFiles = Channel.fromPath( '/crex/proj/uppmax2022-2-10/metabolomics/mzMLData/*.mzML' )
mzMLFiles.collect().view()

```

The above code, will get the files from the path and emit them all at once. You can try this and compare the results to when you don't use collect.


Create a file called `main_13.nf`

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
nano main_13.nf
```

Copy the above code to it. Save the file `(Ctrl+o enter)` and exit `(Ctrl+x)`
Now run 

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
nextflow main_13.nf
```

This operator can also be used inside the process. For example,


```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
mzMLFiles = Channel.fromPath( '/crex/proj/uppmax2022-2-10/metabolomics/mzMLData/*.mzML' )
process featureFinder {
input:
file x from mzMLFiles.collect() #1

""" 
echo $x
"""  
}
outputChannel.view()

```

1. By using `collect()`, the process will gather all the files in `mzMLFiles` channel and do the operation for this collection of files.

Run this example and compare the results to when you don't use collect. What is the difference? How many times the process will be run if you use and don't use collect?

## flatten

The `flatten` operator transforms a channel in such a way that every item of type Collection or `Array` is flattened so that each single entry is emitted separately by the resulting channel. 

for example,


```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
Channel
    .from( [1,[2,3]], 4, [5,[6]] )
    .flatten()
    .view()

```

Try to run this example and compare the results to collect!

# Configuration file


When a pipeline script is launched, Nextflow looks for configuration files in multiple locations. Since each configuration file can contain conflicting settings, the sources are ranked to decide which settings to are applied. All possible configuration sources are reported below, listed in order of priority:

1. Parameters specified on the command line (--something value)

2. Parameters provided using the -params-file option

3. Config file specified using the -c my_config option

4. The config file named nextflow.config in the current directory

5. The config file named nextflow.config in the workflow project directory

6. The config file $HOME/.nextflow/config

7. Values defined within the pipeline script itself (e.g. main.nf)

It is easy to write the config file. It is just a text file wherein you can assign variables. These variables are readily available in the pipeline to use. The comments should be written using `//`

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
propertyOne = 'world'
anotherProp = "Hello $propertyOne"
customPath = "$PATH:/my/app/folder"
// comment!

```

Let's try this config file!

Create a file called `nextflow_14.config` and put the above code in it. 

Create a file called `main_14.nf` and put the following code in it:

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
println propertyOne
println anotherProp
println customPath
```

Save the file (Ctrl+o enter) and exit (Ctrl+x)
Now run the following: 

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
nextflow main_14.nf -c nextflow_14.config
```

## Config scopes

Configuration settings can be organized in different scopes by dot prefixing the property names with a scope identifier or grouping the properties in the same scope using the curly brackets notation.

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
alpha.x  = 1
alpha.y  = 'string value..'

beta {
     p = 2
     q = 'another string ..'
}
```

There are many important default scopes in Nextflow. You can have a look [here](https://www.nextflow.io/docs/latest/config.html#config-scopes).

### Scope params

The params scope allows you to define parameters that will be accessible in the pipeline script. Simply prefix the parameter names with the params scope or surround them by curly brackets. 

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
params {

   mzMLFilesInput = '/crex/proj/uppmax2022-2-10/metabolomics/mzMLData/*.mzML' #1
  ppm_input=10 #2

}

```

In the example above, we define two parameters:

1. `mzMLFilesInput` which points to the location our input files.
2. `ppm_input` which is used in a bash script

We can then use these two parameters anywhere inside our pipeline. For example:

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
mzMLFiles = Channel.fromPath( params.mzMLFilesInput ) #1
process featureFinder {
echo true
input:
file x from mzMLFiles

"echo processing $x with $params.ppm_input ppm" #2

}
```

In this example:
1. We created a file channel using our parameter `params.mzMLFilesInput`
2. We accessed value of `ppm_input` using `$param` before the name of the parameter. 

Try the above code! Create two files, `main_15.nf`  and `nextflow_15.config`. and run the above example!

Pipeline script can use an arbitrary number of parameters that can be *overridden* either using the command line or the Nextflow configuration file. Any script parameter can be specified on the command line prefixing the parameter name with double dash characters e.g.:

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
nextflow run <my script> --foo Hello
```

Then, the parameter can be accessed in the pipeline script using the params.foo identifier.

How would you run the above script so that `ppm_input` is send to the pipeline the command line? 

```{bash, attr.source='.numberLines',eval=FALSE}
nextflow run main_15.nf -c  nextflow_15.config --ppm_input 20
```

What happend with the default value of `ppm_input`?

### Scope process

The process configuration scope allows you to provide the default configuration for the processes in your pipeline.

You can specify here any property described in the [process directive](https://www.nextflow.io/docs/latest/process.html#process-directives) and the executor sections. For example,

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
process {
executor = 'slurm' #1
  clusterOptions = { "-A $params.project ${params.clusterOptions ?: ''}" } #2
}
```

In the example above:
1. We set the `executor` to `slurm` so that all the jobs will be send to `slurm`
2. We set some addition parameters for example `-A` for setting the project ID and `clusterOptions` for additional arguments


### Scope executor

The executor configuration scope allows you to set the optional executor settings.
The executor settings can be defined as shown below:

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
executor {
    name = 'slurm'
    queueSize = 200
    clusterOptions = { "-A $params.project ${params.clusterOptions ?: ''}" }
}
```

When using two (or more) different executors in your pipeline, you can specify their settings separately by prefixing the executor name with the symbol `$` and using it as special scope identifier. For example:

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
executor {
  $slurm {
    queueSize = 200
    clusterOptions = { "-A $params.project ${params.clusterOptions ?: ''}" }
  }

  $local {
      cpus = 8
      memory = '32 GB'
  }
}
```

### Configuration on UPPMAX

UPPMAX uses slurm job scheduler. We can use the process scope to instruct Nextflow to use slurm

Create a file called `nextflow_17.config` with the following content:

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
process.executor = 'slurm'
process.clusterOptions = { "-A $params.project ${params.clusterOptions ?: ''}"}
```

Create a file called `main_17.nf`

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
// This is main.nf
mzMLFiles = Channel.fromPath( '/crex/proj/uppmax2022-2-10/metabolomics/mzMLData/*.mzML' )
process featureFinder {
echo true
input:
file x from mzMLFiles

"echo processing $x"

}
```

You can now run the pipeline using

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
nextflow main_17.nf -c nextflow_17.config --project "uppmax2022-2-10" --clusterOptions "-M snowy" 
```

The process is now running on Uppmax.
OK! This is probably going to take time. Use `Ctrl+c` to kill Nextflow! Then cancel all of your jobs!

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
scancel -u $USER -M snowy
```


### Containers

The docker configuration scope controls how Docker containers are executed by Nextflow

For example 

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
process.container = 'nextflow/examples' #1

docker {
    enabled = true #2
}
```

In the example above:

1. We first set `process.container` to the location of the Docker image for example in Dockerhub.
2. We enable Docker. 

All the processes will then use Docker container.

Similarly we can use singularity. 

Please be aware that if you Nextflow to use a Docker image and convert to singularity image. This process will take time. In order to save you time we have already done the conversion. To use what we have built, first run the following command:

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
export NXF_SINGULARITY_CACHEDIR=/crex/proj/uppmax2022-2-10/metabolomics/singularity
```

The above command will set the location of the image for Nextflow. 

We can later create a file named `nextflow_18.config` with the following content

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
singularity.enabled = true #1
process.container="metaboigniter/course_docker:v5" #2
```

1. Instruct Nextflow to use Singularity
2. Sets the name of the image

We can now create another file ` main_18.nf` with the following content:

```{bash, attr.source='.numberLines',eval=FALSE, class.source="nohide"}
mzMLFiles = Channel.fromPath( '/crex/proj/uppmax2022-2-10/metabolomics/mzMLData/*.mzML' )
process featureFinder {
echo true
input:
file x from mzMLFiles

"echo processing $x"

}
```

Now we can run it using?

```{bash, attr.source='.numberLines',eval=FALSE}
nextflow main_18.nf -c nextflow_18.config 
```

The process is now running using a singularity container!OK! This is taking time! Use `Ctrl+c` to kill Nextflow! Then cancel all of your jobs!

```{bash, attr.source='.numberLines',eval=FALSE}
scancel -u $USER -M snowy
```


